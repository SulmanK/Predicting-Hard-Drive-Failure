{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we create a function to compare the columns of two csv's to drop columns which are not mutual. We will merge the daily csv files into quarterly csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_df_columns_drop(csv_1, csv_2):\n",
    "    \"Function to compare two columns of a dataframe and drop the columns which are not mutual\"\n",
    "    # Load dataframes\n",
    "    dataframe_1 = pd.read_csv(csv_1)\n",
    "    dataframe_2 = pd.read_csv(csv_2)\n",
    "    \n",
    "    # Compare and drop unmutual oclumns\n",
    "    unmutual_columns_df1 = []\n",
    "    unmutual_columns_df2 = []\n",
    "    \n",
    "    # If dataframe 1 has different columns than dataframe 2, drop columns in dataframe 1\n",
    "    for x in dataframe_1.columns.values:\n",
    "        if x not in dataframe_2.columns.values:\n",
    "            unmutual_columns_df1.append(x)\n",
    "            if len(unmutual_columns_df1) > 0:\n",
    "                dataframe_1 = dataframe_1.drop([str(x)], axis = 1)\n",
    "                \n",
    "    # If dataframe 2 has different columns than dataframe 1, drop columns in dataframe 2\n",
    "    for x in dataframe_2.columns.values:\n",
    "        if x not in dataframe_1.columns.values:\n",
    "            unmutual_columns_df2.append(x)\n",
    "            if len(unmutual_columns_df2) > 0:\n",
    "                dataframe_2 = dataframe_2.drop([str(x)], axis = 1)\n",
    "        \n",
    "    return dataframe_1, dataframe_2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1, df_2 = compare_df_columns_drop('data/drive_stats_2019_Q1/2019-01-01.csv',\n",
    "                        'data/data_Q4_2019/2019-10-01.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a function to merge all the daily csv's files into quarterly csv files and then merging it all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged_csv(folder_name, output_name):\n",
    "    \"Function to merge all csv files in a folder\"\n",
    "\n",
    "    # Create empty dataframe with all columns\n",
    "    tmp_df = pd.read_csv('data/drive_stats_2019_Q1/2019-01-01.csv')\n",
    "    columns_df = tmp_df.columns.values\n",
    "    \n",
    "    # Create empty dataframe\n",
    "    df = pd.DataFrame(columns = columns_df )\n",
    "    \n",
    "    # Merge CSV's\n",
    "    folder_name = folder_name\n",
    "    file_type = 'csv'\n",
    "    \n",
    "    unmutual_columns = []\n",
    "    \n",
    "    # Initiliaze all files in the folder\n",
    "    for f in glob.glob(folder_name + \"/*.\" + file_type):\n",
    "        \n",
    "        # If it's the last file in the folder, it will append all entries.\n",
    "        if f == glob.glob(folder_name + \"/*.\" + file_type)[-1]:\n",
    "            tmp_df = pd.read_csv(f)\n",
    "            \n",
    "            # Drop columns that are unmutual\n",
    "            for x in tmp_df.columns.values:\n",
    "                if x not in df.columns.values:\n",
    "                    unmutual_columns.append(x)\n",
    "                    if len(unmutual_columns) > 0:\n",
    "                        tmp_df = tmp_df.drop([str(x)], axis = 1)    \n",
    "                        \n",
    "            df = df.append(tmp_df) \n",
    "            \n",
    "        # If not the last file in the folder, append all entires that failed.\n",
    "        else:\n",
    "            tmp_df = pd.read_csv(f)\n",
    "            df = df.append(tmp_df[tmp_df['failure'] == 1])\n",
    "    \n",
    "    output_name = output_name\n",
    "    df.to_csv(output_name, index = None, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create quarterly files\n",
    "merged_csv('data/drive_stats_2019_Q1', 'data/Q1-2019.csv')\n",
    "merged_csv('data/data_Q2_2019', 'data/Q2-2019.csv')\n",
    "merged_csv('data/data_Q3_2019', 'data/Q3-2019.csv')\n",
    "merged_csv('data/data_Q4_2019', 'data/Q4-2019.csv')\n",
    "merged_csv('data/','data/Full-2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a new csv file to track the number of failures per quarter to track the frequency of failures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_hd_failures(directories):\n",
    "    \"Function which goes through various directories to record the number of hard drives and failures per day amd outputs a csv\"\n",
    "    date_list = []\n",
    "    hard_drives_per_date = []\n",
    "    failures_per_date = []\n",
    "    # Loop through all individual date csv's and record the data\n",
    "    for folder_name in directories:\n",
    "        for f in glob.glob(folder_name + \"/*.\" + 'csv'):\n",
    "            ## Read in dataframe\n",
    "            tmp_df = pd.read_csv(f)\n",
    "\n",
    "            ## Record the date list, the number of hard drives and failures per date. \n",
    "            date_list.append(tmp_df['date'].unique()[0])\n",
    "            hard_drives_per_date.append(tmp_df.shape[0])\n",
    "            failures_per_date.append(len(tmp_df[tmp_df['failure'] == 1]))\n",
    "            \n",
    "    # Create dataframe of recorded data        \n",
    "    data =  {'date': date_list,\n",
    "             'hard_drives': hard_drives_per_date,\n",
    "             'failures': failures_per_date,\n",
    "            }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "            \n",
    "    return df.to_csv('data/daily_hd_failures.csv', index = None, header = True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_hd_failures(['data/drive_stats_2019_Q1', 'data/data_Q2_2019',\n",
    "                        'data/data_Q3_2019', 'data/data_Q4_2019' ] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
